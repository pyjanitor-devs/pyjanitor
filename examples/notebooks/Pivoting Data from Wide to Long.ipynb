{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivot_Longer : One function to cover transformations from wide to long form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import janitor\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpivoting(reshaping data from wide to long form) in Pandas is executed either through [pd.melt](https://pandas.pydata.org/docs/reference/api/pandas.melt.html), [pd.wide_to_long](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.wide_to_long.html), or [pd.DataFrame.stack](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.stack.html). However, there are scenarios where a few more steps are required to massage the data into the long form that we desire. Take the dataframe below, copied from [Stack Overflow](https://stackoverflow.com/questions/64061588/pandas-melt-multiple-columns-to-tabulate-a-dataset#64062002): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "        {\n",
    "            \"id\": [1, 2, 3],\n",
    "            \"M_start_date_1\": [201709, 201709, 201709],\n",
    "            \"M_end_date_1\": [201905, 201905, 201905],\n",
    "            \"M_start_date_2\": [202004, 202004, 202004],\n",
    "            \"M_end_date_2\": [202005, 202005, 202005],\n",
    "            \"F_start_date_1\": [201803, 201803, 201803],\n",
    "            \"F_end_date_1\": [201904, 201904, 201904],\n",
    "            \"F_start_date_2\": [201912, 201912, 201912],\n",
    "            \"F_end_date_2\": [202007, 202007, 202007],\n",
    "        }\n",
    "    )\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a [beautiful solution](https://stackoverflow.com/a/64062027/7175713), from Stack Overflow : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.set_index('id')\n",
    "df1.columns = df1.columns.str.split('_', expand=True)\n",
    "df1 = (df1.stack(level=[0,2,3])\n",
    "          .sort_index(level=[0,1], ascending=[True, False])\n",
    "          .reset_index(level=[2,3], drop=True)\n",
    "          .sort_index(axis=1, ascending=False)\n",
    "          .rename_axis(['id','cod'])\n",
    "          .reset_index())\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We propose an alternative, based on [pandas melt](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html) that abstracts the reshaping mechanism, allows the user to focus on the task, can be applied to other scenarios,  and is chainable : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.pivot_longer(\n",
    "            index=\"id\", \n",
    "            names_to=(\"cod\", \".value\"), \n",
    "            names_pattern=\"(M|F)_(start|end)_.+\", \n",
    "            sort_by_appearance=True,\n",
    "            )\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.equals(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[pivot_longer](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.pivot_longer.html#janitor.pivot_longer) is not a new idea; it is a combination of ideas from R's [tidyr](https://tidyr.tidyverse.org/reference/pivot_longer.html) and [data.table](https://rdatatable.gitlab.io/data.table/) and is built on the powerful pandas' [melt](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html) function. \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[pivot_longer](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.pivot_longer.html#janitor.pivot_longer) can melt dataframes easily; It is just a wrapper around pandas' [melt](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html).\n",
    "\n",
    "[Source Data](https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html#reshaping-by-melt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.MultiIndex.from_tuples([('person', 'A'), ('person', 'B')])\n",
    "\n",
    "df = pd.DataFrame({'first': ['John', 'Mary'],\n",
    "                   'last': ['Doe', 'Bo'],\n",
    "                   'height': [5.5, 6.0],\n",
    "                   'weight': [130, 150]},\n",
    "                   index=index)\n",
    "                   \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(index=['first','last'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want the data unpivoted in order of appearance, you can set `sort_by_appearance` to ``True``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(\n",
    "    index=['first','last'],\n",
    "    sort_by_appearance = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to reuse the original index, you can set `ignore_index` to ``False``; note that the index labels will be repeated as necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(\n",
    "    index=['first','last'],\n",
    "    ignore_index = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also unpivot MultiIndex columns, the same way you would with pandas' [melt](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html#pandas.melt):\n",
    "\n",
    "[Source Data](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html#pandas.melt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},\n",
    "                   'B': {0: 1, 1: 3, 2: 5},\n",
    "                   'C': {0: 2, 1: 4, 2: 6}})\n",
    "df.columns = [list('ABC'), list('DEF')]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(\n",
    "    index = [(\"A\", \"D\")],\n",
    "    values_to = \"num\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(\n",
    "    index = [(\"A\", \"D\")],\n",
    "    column_names = [(\"B\", \"E\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just like [melt](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html#pandas.melt), you can unpivot on a specific level, with `column_level`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(\n",
    "    index = \"A\",\n",
    "    column_names = \"B\",\n",
    "    column_level = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when unpivoting MultiIndex columns, you need to pass a list of tuples to the ``index`` or ``column_names`` parameters.\n",
    "\n",
    "\n",
    "Also, if ``names_sep`` or ``names_pattern`` is not None, then unpivoting on MultiIndex columns is not supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can dynamically select columns, using regular expressions with the `janitor.patterns` function (inspired by R's data.table's [patterns](https://rdatatable.gitlab.io/data.table/reference/patterns.html) function, and is really just a wrapper around `re.compile`), especially if it is a lot of column names, and you are *lazy* like me  ðŸ˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/tidyverse/tidyr/raw/master/data-raw/billboard.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpivot all columns that start with 'wk'\n",
    "df.pivot_longer(column_names = janitor.patterns(\"^(wk)\"), \n",
    "                names_to='week')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use [pyjanitor's](https://pyjanitor.readthedocs.io/) [select_columns](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.select_columns.html#janitor.select_columns) syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(column_names = \"wk*\", \n",
    "                names_to = 'week')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[pivot_longer](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.pivot_longer.html#janitor.pivot_longer) can also unpivot paired columns.  In this regard, it is like pandas' [wide_to_long](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.wide_to_long.html), but with more flexibility and power. Let's look at an example from pandas' [wide_to_long](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.wide_to_long.html) docs : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'famid': [1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
    "    'birth': [1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
    "    'ht1': [2.8, 2.9, 2.2, 2, 1.8, 1.9, 2.2, 2.3, 2.1],\n",
    "    'ht2': [3.4, 3.8, 2.9, 3.2, 2.8, 2.4, 3.3, 3.4, 2.9]\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data above, the `height`(ht) is paired with `age`(numbers). [pd.wide_to_long](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.wide_to_long.html) can handle this easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.wide_to_long(df, stubnames='ht', i=['famid', 'birth'], j='age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how [pivot_longer](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.pivot_longer.html#janitor.pivot_longer) handles this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(index=['famid','birth'],\n",
    "                names_to=('.value', 'age'),\n",
    "                names_pattern=r\"(ht)(\\d)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first observable difference is that [pivot_longer](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.pivot_longer.html#janitor.pivot_longer) is method chainable, while [pd.wide_to_long](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.wide_to_long.html) is not. Now, let's learn more about the `.value` variable.\n",
    "\n",
    "\n",
    "When `.value` is used in `names_to`, a pairing is created between ``names_to`` and ``names_pattern``. For the example above, we get this pairing :\n",
    "\n",
    "                                          {\".value\": (\"ht\"), \"age\": (\\d)} \n",
    "\n",
    "This tells the [pivot_longer](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.pivot_longer.html#janitor.pivot_longer) function to keep values associated with `.value`(`ht`) as the column name, while values not associated with `.value`, in this case, the numbers, will be collated under a new column ``age``. Internally, pandas `str.extract` is used to get the capturing groups before reshaping. This level of abstraction, we believe, allows the user to focus on the task, and get things done faster.\n",
    "\n",
    "Note that if you want the data returned in order of appearance you can set `sort_by_appearance` to `True`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(\n",
    "    index = ['famid','birth'],\n",
    "    names_to = ('.value', 'age'),\n",
    "    names_pattern = r\"(ht)(\\d)\",                 \n",
    "    sort_by_appearance = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you are likely to get more speed when `sort_by_appearance` is ``False``.\n",
    "\n",
    "Note also that the values in the `age` column are of `object` dtype. You can change the dtype, using pandas' [astype](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html) method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've seen already that [pd.wide_to_long](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.wide_to_long.html) handles this already and very well, so why bother? Let's look at another scenario where [pd.wide_to_long](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.wide_to_long.html) would need a few more steps. [Source Data](https://community.rstudio.com/t/pivot-longer-on-multiple-column-sets-pairs/43958):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"off_loc\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"],\n",
    "        \"pt_loc\": [\"G\", \"H\", \"I\", \"J\", \"K\", \"L\"],\n",
    "        \"pt_lat\": [\n",
    "            100.07548220000001,\n",
    "            75.191326,\n",
    "            122.65134479999999,\n",
    "            124.13553329999999,\n",
    "            124.13553329999999,\n",
    "            124.01028909999998,\n",
    "        ],\n",
    "        \"off_lat\": [\n",
    "            121.271083,\n",
    "            75.93845266,\n",
    "            135.043791,\n",
    "            134.51128400000002,\n",
    "            134.484374,\n",
    "            137.962195,\n",
    "        ],\n",
    "        \"pt_long\": [\n",
    "            4.472089953,\n",
    "            -144.387785,\n",
    "            -40.45611048,\n",
    "            -46.07156181,\n",
    "            -46.07156181,\n",
    "            -46.01594293,\n",
    "        ],\n",
    "        \"off_long\": [\n",
    "            -7.188632000000001,\n",
    "            -143.2288569,\n",
    "            21.242563,\n",
    "            40.937416999999996,\n",
    "            40.78472,\n",
    "            22.905889000000002,\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can unpivot with [pd.wide_to_long](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.wide_to_long.html) by first reorganising the columns : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "df1.columns = [\"_\".join(col.split(\"_\")[::-1])\n",
    "               for col in df1.columns]\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can unpivot : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.wide_to_long(\n",
    "    df1.reset_index(),\n",
    "    stubnames=[\"loc\", \"lat\", \"long\"],\n",
    "    sep=\"_\",\n",
    "    i=\"index\",\n",
    "    j=\"set\",\n",
    "    suffix=\".+\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the same transformed dataframe, with less lines, using [pivot_longer](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.pivot_longer.html#janitor.pivot_longer) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.pivot_longer(\n",
    "    names_to = [\"set\", \".value\"], \n",
    "    names_pattern = \"(.+)_(.+)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to see the pairings, \n",
    "# to see what is linked to `.value`, \n",
    "\n",
    "# names_to =     [\"set\", \".value\"]\n",
    "# names_pattern = \"(.+)_(.+)\"\n",
    "# column _names =   off_loc\n",
    "#                   off_lat\n",
    "#                   off_long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the key here is the `.value` symbol. Pairing `names_to` with `names_pattern` and its results from [pd.str.extract](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.extract.html), we get : \n",
    "\n",
    "                            set--> (.+) --> [off, pt] and \n",
    "                            .value--> (.+) --> [loc, lat, long] \n",
    "                                           \n",
    "All values associated with `.value`(loc, lat, long) remain as column names, while values not associated with `.value`(off, pt) are lumped into a new column ``set``. \n",
    "\n",
    "Notice that we did not have to reset the index - [pivot_longer](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.pivot_longer.html#janitor.pivot_longer) takes care of that internally;  [pivot_longer](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.pivot_longer.html#janitor.pivot_longer) allows you to focus on what you want, so you can get it and move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the unpivoting could also have been executed with `names_sep`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(\n",
    "    names_to = [\"set\", \".value\"], \n",
    "    names_sep = \"_\",\n",
    "    ignore_index = False,\n",
    "    sort_by_appearance = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at another example, from [Stack Overflow](https://stackoverflow.com/questions/45123924/convert-pandas-dataframe-from-wide-to-long/45124130) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([{'a_1': 2, 'ab_1': 3, \n",
    "                    'ac_1': 4, 'a_2': 5, \n",
    "                    'ab_2': 6, 'ac_2': 7}])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data above requires extracting `a`, `ab` and `ac` from `1` and `2`. This is another example of a paired column. We could solve this using [pd.wide_to_long](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.wide_to_long.html); infact there is a very good solution from [Stack Overflow](https://stackoverflow.com/a/45124775/7175713)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "df1['id'] = df1.index\n",
    "pd.wide_to_long(df1, ['a','ab','ac'],i='id',j='num',sep='_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you could simply pass the buck to [pivot_longer](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.pivot_longer.html#janitor.pivot_longer) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.pivot_longer(\n",
    "    names_to = ('.value', 'num'), \n",
    "    names_sep = '_'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the solution above, we used the `names_sep` argument, as it is more convenient. A few more examples to get you familiar with the `.value` symbol.\n",
    "\n",
    "[Source Data](https://stackoverflow.com/questions/55403008/pandas-partial-melt-or-group-melt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1,1,2,3,4,5,6],\n",
    "                   [2,7,8,9,10,11,12]], \n",
    "                  columns=['id', 'ax','ay','az','bx','by','bz'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(\n",
    "    index = 'id', \n",
    "    names_to = ('name', '.value'), \n",
    "    names_pattern = '(.)(.)'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the code above `.value` is paired with `x`, `y`, `z`(which become the new column names), while `a`, `b` are unpivoted into the `name` column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataframe below, we need to unpivot the data, keeping only the suffix `hi`, and pulling out the number between `A` and `g`. [Source Data](https://stackoverflow.com/questions/35929985/melt-a-data-table-with-a-column-pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([{'id': 1, 'A1g_hi': 2, \n",
    "                    'A2g_hi': 3, 'A3g_hi': 4, \n",
    "                    'A4g_hi': 5}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(\n",
    "    index = 'id', \n",
    "    names_to = ['time','.value'], \n",
    "    names_pattern = \"A(\\d)g_(hi)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see an example where we have multiple values in a paired column, and we wish to split them into separate columns. [Source Data](https://stackoverflow.com/questions/64107566/how-to-pivot-longer-and-populate-with-fields-from-column-names-at-the-same-tim?noredirect=1#comment113369419_64107566) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Sony | TV | Model | value\": {0: \"A222\", 1: \"A234\", 2: \"A4345\"},\n",
    "        \"Sony | TV | Quantity | value\": {0: 5, 1: 5, 2: 4},\n",
    "        \"Sony | TV | Max-quant | value\": {0: 10, 1: 9, 2: 9},\n",
    "        \"Panasonic | TV | Model | value\": {0: \"T232\", 1: \"S3424\", 2: \"X3421\"},\n",
    "        \"Panasonic | TV | Quantity | value\": {0: 1, 1: 5, 2: 1},\n",
    "        \"Panasonic | TV | Max-quant | value\": {0: 10, 1: 12, 2: 11},\n",
    "        \"Sanyo | Radio | Model | value\": {0: \"S111\", 1: \"S1s1\", 2: \"S1s2\"},\n",
    "        \"Sanyo | Radio | Quantity | value\": {0: 4, 1: 2, 2: 4},\n",
    "        \"Sanyo | Radio | Max-quant | value\": {0: 9, 1: 9, 2: 10},\n",
    "    }\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to reshape the data into long format, with separate columns for `Manufacturer`(Sony,...), `Device`(TV, Radio), `Model`(S3424, ...), ``maximum quantity`` and ``quantity``. \n",
    "\n",
    "Below is the [accepted solution](https://stackoverflow.com/a/64107688/7175713) on Stack Overflow :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "# Create a multiIndex column header\n",
    "df1.columns = pd.MultiIndex.from_arrays(\n",
    "    zip(*df1.columns.str.split(\"\\s?\\|\\s?\"))\n",
    ")\n",
    "\n",
    "# Reshape the dataframe using \n",
    "# `set_index`, `droplevel`, and `stack`\n",
    "(df1.stack([0, 1])\n",
    " .droplevel(1, axis=1)\n",
    " .set_index(\"Model\", append=True)\n",
    " .rename_axis([None, \"Manufacturer\", \"Device\", \"Model\"])\n",
    " .sort_index(level=[1, 2, 3])\n",
    " .reset_index()\n",
    " .drop(\"level_0\", axis=1)\n",
    " )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we could use [pivot_longer](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.pivot_longer.html#janitor.pivot_longer), along with `.value` in `names_to` and a regular expression in `names_pattern` : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(\n",
    "    names_to = (\"Manufacturer\", \"Device\", \".value\"),\n",
    "    names_pattern = r\"(.+)\\|(.+)\\|(.+)\\|.*\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cleanup (removal of whitespace in the column names) is left as an exercise for the reader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we are interested in unpivoting only a part of the entire dataframe? [Source Data](https://stackoverflow.com/questions/63044119/converting-wide-format-data-into-long-format-with-multiple-indices-and-grouped-d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'time': [1, 2, 3], \n",
    "                   'factor': ['a','a','b'],\n",
    "                   'variable1': [0,0,0],\n",
    "                   'variable2': [0,0,1],\n",
    "                   'variable3': [0,2,0],\n",
    "                   'variable4': [2,0,1],\n",
    "                   'variable5': [1,0,1],\n",
    "                   'variable6': [0,1,1],                   \n",
    "                   'O1V1': [0,0.2,-0.3],\n",
    "                   'O1V2': [0,0.4,-0.9],\n",
    "                   'O1V3': [0.5,0.2,-0.6],\n",
    "                   'O1V4': [0.5,0.2,-0.6],\n",
    "                   'O1V5': [0,0.2,-0.3],\n",
    "                   'O1V6': [0,0.4,-0.9],\n",
    "                   'O1V7': [0.5,0.2,-0.6],\n",
    "                   'O1V8': [0.5,0.2,-0.6],                   \n",
    "                   'O2V1': [0,0.5,0.3],\n",
    "                   'O2V2': [0,0.2,0.9],\n",
    "                   'O2V3': [0.6,0.1,-0.3],\n",
    "                   'O2V4': [0.5,0.2,-0.6],\n",
    "                   'O2V5': [0,0.5,0.3],\n",
    "                   'O2V6': [0,0.2,0.9],\n",
    "                   'O2V7': [0.6,0.1,-0.3],\n",
    "                   'O2V8': [0.5,0.2,-0.6],                   \n",
    "                   'O3V1': [0,0.7,0.4],\n",
    "                   'O3V2': [0.9,0.2,-0.3],\n",
    "                   'O3V3': [0.5,0.2,-0.7],\n",
    "                   'O3V4': [0.5,0.2,-0.6],\n",
    "                   'O3V5': [0,0.7,0.4],\n",
    "                   'O3V6': [0.9,0.2,-0.3],\n",
    "                   'O3V7': [0.5,0.2,-0.7],\n",
    "                   'O3V8': [0.5,0.2,-0.6]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the task? This is copied verbatim from the source:\n",
    "\n",
    "<blockquote>Each row of the data frame represents a time period. There are multiple 'subjects' being monitored, namely O1, O2, and O3. Each subject has 8 variables being measured. I need to convert this data into long format where each row contains the information for one subject at a given time period, but with only the first 4 subject variables, as well as the extra information about this time period in columns 2-4, but not columns 5-8.</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the accepted solution, using [wide_to_long](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.wide_to_long.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.rename(columns={x: x[2:]+x[1:2] for x in df.columns[df.columns.str.startswith('O')]})\n",
    "\n",
    "df1 = pd.wide_to_long(df1, i=['time', 'factor']+[f'variable{i}' for i in range(1,7)], \n",
    "                      j='id', stubnames=[f'V{i}' for i in range(1,9)], suffix='.*')\n",
    "\n",
    "df1 = (df1.reset_index()\n",
    "          .drop(columns=[f'V{i}' for i in range(5,9)]\n",
    "                        +[f'variable{i}' for i in range(3,7)]))\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can abstract the details and focus on the task with [pivot_longer]([pivot_longer](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.pivot_longer.html#janitor.pivot_longer)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(\n",
    "    index = slice(\"time\", \"variable2\"),\n",
    "    column_names = janitor.patterns(\".+V[1-4]$\"),\n",
    "    names_to = (\"id\", \".value\"),\n",
    "    names_pattern = \".(.)(.+)$\",\n",
    "    sort_by_appearance = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more example on the `.value` symbol for paired columns [Source Data](https://stackoverflow.com/questions/59477686/python-pandas-melt-single-column-into-two-seperate) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id': [1, 2], \n",
    "                   'A_value': [50, 33], \n",
    "                   'D_value': [60, 45]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(\n",
    "    index = 'id', \n",
    "    names_to = ('value_type', '.value'), \n",
    "    names_sep = '_'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are scenarios where we need to unpivot the data, and group values within the column names under new columns. The values in the columns will not become new column names, so we do not need the `.value` symbol. Let's see an example below: [Source Data](https://stackoverflow.com/questions/59550804/melt-column-by-substring-of-the-columns-name-in-pandas-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'subject': [1, 2],\n",
    "                   'A_target_word_gd': [1, 11],\n",
    "                   'A_target_word_fd': [2, 12],\n",
    "                   'B_target_word_gd': [3, 13],\n",
    "                   'B_target_word_fd': [4, 14],\n",
    "                   'subject_type': ['mild', 'moderate']})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataframe above, `A` and `B` represent conditions, while the suffixes `gd` and `fd` represent value types. We are not interested in the words in the middle (`_target_word`). We could solve it this way (this is the chosen solution, copied from [Stack Overflow](https://stackoverflow.com/a/59550967/7175713)) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df =(pd.melt(df,\n",
    "                id_vars=['subject_type','subject'], \n",
    "                var_name='abc')\n",
    "           .sort_values(by=['subject', 'subject_type'])\n",
    "         )\n",
    "new_df['cond']=(new_df['abc']\n",
    "                .apply(lambda x: (x.split('_'))[0])\n",
    "                )\n",
    "new_df['value_type']=(new_df\n",
    "                      .pop('abc')\n",
    "                      .apply(lambda x: (x.split('_'))[-1])\n",
    "                      )\n",
    "new_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we could just pass the buck to [pivot_longer](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.pivot_longer.html#janitor.pivot_longer) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(\n",
    "    index = [\"subject\", \"subject_type\"],\n",
    "    names_to = (\"cond\", \"value_type\"),\n",
    "    names_pattern = \"([A-Z]).*(gd|fd)\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, we pass in the new names of the columns to `names_to`('cond', 'value_type'), and pass the groups to be extracted as a regular expression to `names_pattern`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's another example where [pivot_longer](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.pivot_longer.html#janitor.pivot_longer) abstracts the process and makes reshaping easy.\n",
    "\n",
    "\n",
    "In the dataframe below, we would like to unpivot the data and separate the column names into individual columns(`vault` should be in an `event` column, `2012` should be in a `year` column and `f` should be in a `gender` column). [Source Data](https://dcl-wrangle.stanford.edu/pivot-advanced.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "            {\n",
    "                \"country\": [\"United States\", \"Russia\", \"China\"],\n",
    "                \"vault_2012_f\": [\n",
    "                    48.132,\n",
    "                    46.366,\n",
    "                    44.266,\n",
    "                ],\n",
    "                \"vault_2012_m\": [46.632, 46.866, 48.316],\n",
    "                \"vault_2016_f\": [\n",
    "                    46.866,\n",
    "                    45.733,\n",
    "                    44.332,\n",
    "                ],\n",
    "                \"vault_2016_m\": [45.865, 46.033, 45.0],\n",
    "                \"floor_2012_f\": [45.366, 41.599, 40.833],\n",
    "                \"floor_2012_m\": [45.266, 45.308, 45.133],\n",
    "                \"floor_2016_f\": [45.999, 42.032, 42.066],\n",
    "                \"floor_2016_m\": [43.757, 44.766, 43.799],\n",
    "            }\n",
    "        )\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could achieve this with a combination of [pd.melt](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html) and pandas string methods (or janitor's [deconcatenate_columns](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.deconcatenate_column.html#janitor.deconcatenate_column) method); or we could, again, pass the buck to [pivot_longer](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.pivot_longer.html#janitor.pivot_longer) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(\n",
    "    index = \"country\",\n",
    "    names_to = [\"event\", \"year\", \"gender\"],\n",
    "    names_sep = \"_\",\n",
    "    values_to = \"score\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, if you want the data returned in order of appearance, you can turn on the `sort_by_appearance` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(\n",
    "    index = \"country\",\n",
    "    names_to = [\"event\", \"year\", \"gender\"],\n",
    "    names_sep = \"_\",\n",
    "    values_to = \"score\",\n",
    "    sort_by_appearance = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more feature that [pivot_longer](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.pivot_longer.html#janitor.pivot_longer) offers is to pass a list of regular expressions to `names_pattern`. This comes in handy when one single regex cannot encapsulate similar columns for reshaping to long form. This idea is inspired by the [melt](https://rdatatable.gitlab.io/data.table/reference/melt.data.table.html) function in R's [data.table](https://rdatatable.gitlab.io/data.table/). A couple of examples should make this clear.\n",
    "\n",
    "[Source Data](https://stackoverflow.com/questions/61138600/tidy-dataset-with-pivot-longer-multiple-columns-into-two-columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    [{'title': 'Avatar',\n",
    "  'actor_1': 'CCH_Poundâ€¦',\n",
    "  'actor_2': 'Joel_Daviâ€¦',\n",
    "  'actor_3': 'Wes_Studi',\n",
    "  'actor_1_FB_likes': 1000,\n",
    "  'actor_2_FB_likes': 936,\n",
    "  'actor_3_FB_likes': 855},\n",
    " {'title': 'Pirates_of_the_Carâ€¦',\n",
    "  'actor_1': 'Johnny_Deâ€¦',\n",
    "  'actor_2': 'Orlando_Bâ€¦',\n",
    "  'actor_3': 'Jack_Davenâ€¦',\n",
    "  'actor_1_FB_likes': 40000,\n",
    "  'actor_2_FB_likes': 5000,\n",
    "  'actor_3_FB_likes': 1000},\n",
    " {'title': 'The_Dark_Knight_Riâ€¦',\n",
    "  'actor_1': 'Tom_Hardy',\n",
    "  'actor_2': 'Christianâ€¦',\n",
    "  'actor_3': 'Joseph_Gorâ€¦',\n",
    "  'actor_1_FB_likes': 27000,\n",
    "  'actor_2_FB_likes': 23000,\n",
    "  'actor_3_FB_likes': 23000},\n",
    " {'title': 'John_Carter',\n",
    "  'actor_1': 'Daryl_Sabâ€¦',\n",
    "  'actor_2': 'Samantha_â€¦',\n",
    "  'actor_3': 'Polly_Walkâ€¦',\n",
    "  'actor_1_FB_likes': 640,\n",
    "  'actor_2_FB_likes': 632,\n",
    "  'actor_3_FB_likes': 530},\n",
    " {'title': 'Spider-Man_3',\n",
    "  'actor_1': 'J.K._Simmâ€¦',\n",
    "  'actor_2': 'James_Fraâ€¦',\n",
    "  'actor_3': 'Kirsten_Duâ€¦',\n",
    "  'actor_1_FB_likes': 24000,\n",
    "  'actor_2_FB_likes': 11000,\n",
    "  'actor_3_FB_likes': 4000},\n",
    " {'title': 'Tangled',\n",
    "  'actor_1': 'Brad_Garrâ€¦',\n",
    "  'actor_2': 'Donna_Murâ€¦',\n",
    "  'actor_3': 'M.C._Gainey',\n",
    "  'actor_1_FB_likes': 799,\n",
    "  'actor_2_FB_likes': 553,\n",
    "  'actor_3_FB_likes': 284}]\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have a dataframe of movie titles, actors, and their facebook likes. It would be great if we could transform this into a long form, with just the title, the actor names, and the number of likes. Let's look at a possible solution : \n",
    "\n",
    "First, we reshape the columns, so that the numbers appear at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "pat = r\"(?P<actor>.+)_(?P<num>\\d)_(?P<likes>.+)\"\n",
    "repl = lambda m: f\"\"\"{m.group('actor')}_{m.group('likes')}_{m.group('num')}\"\"\"\n",
    "df1.columns = df1.columns.str.replace(pat, repl)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can reshape, using [pd.wide_to_long](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.wide_to_long.html) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.wide_to_long(df1, \n",
    "               stubnames = ['actor', 'actor_FB_likes'], \n",
    "               i = 'title', \n",
    "               j = 'group', \n",
    "               sep = '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could attempt to solve it with [pivot_longer](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.pivot_longer.html#janitor.pivot_longer), using the `.value` symbol : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.pivot_longer(\n",
    "    index = 'title', \n",
    "    names_to = (\".value\", \"group\"), \n",
    "    names_pattern = \"(.+)_(\\d)$\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we could just get our data in long form without the massaging? We know our data has a pattern to it --> it either ends in a number or *likes*.  Can't we take advantage of that? Yes, we can(I know, I know; it sounds like a campaign slogan ðŸ¤ª)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(\n",
    "    index = 'title',\n",
    "    names_to = (\"actor\", \"num_likes\"),\n",
    "    names_pattern = ('\\d$', 'likes$'),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pairing of `names_to` and `names_pattern` results in :\n",
    "\n",
    "                                   {\"actor\": '\\d$', \"num_likes\": 'likes$'}\n",
    "                                   \n",
    "The first regex looks for columns that end with a number, while the other looks for columns that end with *likes*. [pivot_longer](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.pivot_longer.html#janitor.pivot_longer) will then look for columns that end with a number and lump all the values in those columns under the `actor` column, and also look for columns that end with *like* and combine all the values in those columns into a new column -> `num_likes`. Underneath the hood, [numpy select](https://numpy.org/doc/stable/reference/generated/numpy.select.html) and [pd.Series.str.contains](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.contains.html) are used to pull apart the columns into the new columns. \n",
    "\n",
    "Again, it is about the goal; we are not interested in the numbers (1,2,3), we only need the names of the actors, and their facebook likes. [pivot_longer](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.pivot_longer.html#janitor.pivot_longer) aims to give as much flexibility as possible, in addition to ease of use, to allow the end user focus on the task. \n",
    "\n",
    "Let's take a look at another example. [Source Data](https://stackoverflow.com/questions/60439749/pair-wise-melt-in-pandas-dataframe) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id': [0, 1],\n",
    " 'Name': ['ABC', 'XYZ'],\n",
    " 'code': [1, 2],\n",
    " 'code1': [4, np.nan],\n",
    " 'code2': ['8', 5],\n",
    " 'type': ['S', 'R'],\n",
    " 'type1': ['E', np.nan],\n",
    " 'type2': ['T', 'U']})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot directly use [pd.wide_to_long](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.wide_to_long.html) here without some massaging, as there is no definite suffix(the first `code` does not have a suffix), neither can we use `.value` here, again because there is no suffix. However, we can see a pattern where some columns start with `code`, and others start with `type`. Let's see how [pivot_longer](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.pivot_longer.html#janitor.pivot_longer) solves this, using a sequence of regular expressions in the ``names_pattern`` argument : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(\n",
    "    index = [\"id\", \"Name\"],\n",
    "    names_to = (\"code_all\", \"type_all\"), \n",
    "    names_pattern = (\"^code\", \"^type\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key here is passing the right regular expression, and ensuring the names in `names_to` is paired with the right regex in `names_pattern`; as such, every column that starts with `code` will be included in the new `code_all` column; the same happens to the `type_all` column. Easy and flexible, right? \n",
    "\n",
    "Let's explore another example, from [Stack Overflow](https://stackoverflow.com/questions/12466493/reshaping-multiple-sets-of-measurement-columns-wide-format-into-single-columns) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "            [\n",
    "                {\n",
    "                    \"ID\": 1,\n",
    "                    \"DateRange1Start\": \"1/1/90\",\n",
    "                    \"DateRange1End\": \"3/1/90\",\n",
    "                    \"Value1\": 4.4,\n",
    "                    \"DateRange2Start\": \"4/5/91\",\n",
    "                    \"DateRange2End\": \"6/7/91\",\n",
    "                    \"Value2\": 6.2,\n",
    "                    \"DateRange3Start\": \"5/5/95\",\n",
    "                    \"DateRange3End\": \"6/6/96\",\n",
    "                    \"Value3\": 3.3,\n",
    "                }\n",
    "            ])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataframe above, we need to reshape the data to have a start date, end date and value. For the `DateRange` columns, the numbers are embedded within the string, while for `value` it is appended at the end. One possible solution is to reshape the columns so that the numbers are at the end :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "pat = r\"(?P<head>.+)(?P<num>\\d)(?P<tail>.+)\"\n",
    "repl = lambda m: f\"\"\"{m.group('head')}{m.group('tail')}{m.group('num')}\"\"\"\n",
    "df1.columns = df1.columns.str.replace(pat,repl)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can unpivot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.wide_to_long(df1, \n",
    "                stubnames = ['DateRangeStart', \n",
    "                             'DateRangeEnd', \n",
    "                             'Value'],\n",
    "                i = 'ID', \n",
    "                j = 'num')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `.value` symbol in pivot_longer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.pivot_longer(\n",
    "    index = 'ID', \n",
    "    names_to = [\".value\",'num'], \n",
    "    names_pattern = \"(.+)(\\d)$\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we could allow pivot_longer worry about the massaging; simply pass to `names_pattern` a list of regular expressions that match what we are after : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(\n",
    "    index = 'ID', \n",
    "    names_to = (\"DateRangeStart\", \"DateRangeEnd\", \"Value\"), \n",
    "    names_pattern = (\"Start$\", \"End$\", \"^Value\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above looks for columns that end with *Start*(`Start$`), aggregates all the values in those columns into `DateRangeStart` column, looks for columns that end with *End*(`End$`), aggregates all the values within those columns into `DateRangeEnd` column, and finally looks for columns that start with *Value*(`^Value`), and aggregates the values in those columns into the `Value` column. Just know the patterns, and pair them accordingly. Again, the goal is a focus on the task, to make it simple for the end user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at another example [Source Data](https://stackoverflow.com/questions/64316129/how-to-efficiently-melt-multiple-columns-using-the-module-melt-in-pandas/64316306#64316306) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Activity': ['P1', 'P2'],\n",
    " 'General': ['AA', 'BB'],\n",
    " 'm1': ['A1', 'B1'],\n",
    " 't1': ['TA1', 'TB1'],\n",
    " 'm2': ['A2', 'B2'],\n",
    " 't2': ['TA2', 'TB2'],\n",
    " 'm3': ['A3', 'B3'],\n",
    " 't3': ['TA3', 'TB3']})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a [solution](https://stackoverflow.com/a/64316306/7175713) provided by yours truly : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " (pd.wide_to_long(df, \n",
    "                  i = [\"Activity\", \"General\"], \n",
    "                  stubnames = [\"t\", \"m\"], \n",
    "                  j = \"number\")\n",
    "    .set_axis([\"Task\", \"M\"], \n",
    "              axis = \"columns\")\n",
    "    .droplevel(-1)\n",
    "    .reset_index()\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we could use [pivot_longer](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.pivot_longer.html#janitor.pivot_longer), abstract the details, and focus on the task : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(\n",
    "    index = ['Activity','General'], \n",
    "    names_pattern = ['^m','^t'],\n",
    "    names_to = ['M','Task']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, one last example : \n",
    "\n",
    "\n",
    "[Source Data](https://stackoverflow.com/questions/64159054/how-do-you-pivot-longer-columns-in-groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Name': ['John', 'Chris', 'Alex'],\n",
    " 'activity1': ['Birthday', 'Sleep Over', 'Track Race'],\n",
    " 'number_activity_1': [1, 2, 4],\n",
    " 'attendees1': [14, 18, 100],\n",
    " 'activity2': ['Sleep Over', 'Painting', 'Birthday'],\n",
    " 'number_activity_2': [4, 5, 1],\n",
    " 'attendees2': [10, 8, 5]})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task here is to unpivot the data, and group the data under three new columns (\"activity\", \"number_activity\", and \"attendees\"). \n",
    "\n",
    "We can see that there is a pattern to the data; let's create a list of regular expressions that match the patterns and pass to ``names_pattern``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(\n",
    "    index = 'Name',\n",
    "    names_to = ('activity','number_activity','attendees'), \n",
    "    names_pattern = (\"^activity\",\"^number_activity\",\"^attendees\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, let's look at one final example:\n",
    "\n",
    "\n",
    "[Source Data](https://stackoverflow.com/questions/60387077/reshaping-and-melting-dataframe-whilst-picking-up-certain-regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Location': ['Madrid', 'Madrid', 'Rome', 'Rome'],\n",
    " 'Account': ['ABC', 'XYX', 'ABC', 'XYX'],\n",
    " 'Y2019:MTD:January:Expense': [4354, 769867, 434654, 632556456],\n",
    " 'Y2019:MTD:January:Income': [56456, 32556456, 5214, 46724423],\n",
    " 'Y2019:MTD:February:Expense': [235423, 6785423, 235423, 46588]})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_longer(index = ['Location','Account'],\n",
    "                names_to=(\"year\", \"month\", \".value\"),\n",
    "                names_pattern=r\"Y(.+):MTD:(.{3}).+(Income|Expense)\",\n",
    "                sort_by_appearance=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[pivot_longer](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.pivot_longer.html#janitor.pivot_longer) does not solve all problems; no function does. Its aim is to make it easy to unpivot dataframes from wide to long form, while offering a lot of flexibility and power."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
