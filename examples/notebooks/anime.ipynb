{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Anime Data \n",
    "\n",
    "## Background\n",
    "\n",
    "We will use pyjanitor to showcase how to conveniently chain methods together to perform data cleaning in one shot. We \n",
    "We first define and register a series of dataframe methods with pandas_flavor. Then we chain the dataframe methods together with pyjanitor methods to complete the data cleaning process. The below example shows a one-shot script followed by a step-by-step detail of each part of the method chain.\n",
    "\n",
    "We have adapted a [TidyTuesday analysis](https://github.com/rfordatascience/tidytuesday/blob/master/data/2019/2019-04-23/readme.md) that was originally performed in R. The original text from TidyTuesday will be shown in blockquotes.\n",
    "\n",
    "Note: TidyTuesday is based on the principles discussed and made popular by Hadley Wickham in his paper [Tidy Data](https://www.jstatsoft.org/index.php/jss/article/view/v059i10/v59i10.pdf).\n",
    "\n",
    "*The original text from TidyTuesday will be shown in blockquotes.*\n",
    "Here is a description of the Anime data set that we will use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">This week's data comes from [Tam Nguyen](https://github.com/tamdrashtri) and [MyAnimeList.net via Kaggle](https://www.kaggle.com/aludosan/myanimelist-anime-dataset-as-20190204). [According to Wikipedia](https://en.wikipedia.org/wiki/MyAnimeList) - \"MyAnimeList, often abbreviated as MAL, is an anime and manga social networking and social cataloging application website. The site provides its users with a list-like system to organize and score anime and manga. It facilitates finding users who share similar tastes and provides a large database on anime and manga. The site claims to have 4.4 million anime and 775,000 manga entries. In 2015, the site received 120 million visitors a month.\"\n",
    ">\n",
    ">Anime without rankings or popularity scores were excluded. Producers, genre, and studio were converted from lists to tidy observations, so there will be repetitions of shows with multiple producers, genres, etc. The raw data is also uploaded.\n",
    ">\n",
    ">Lots of interesting ways to explore the data this week!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pyjanitor and pandas\n",
    "import janitor\n",
    "import pandas as pd\n",
    "import pandas_flavor as pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress user warnings when we try overwriting our custom pandas flavor functions\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/raw_anime.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "\n",
    "@pf.register_dataframe_method\n",
    "def str_remove(df, column_name: str, pat: str, *args, **kwargs):\n",
    "    \"\"\"Wrapper around df.str.replace\"\"\"\n",
    "\n",
    "    df[column_name] = df[column_name].str.replace(pat, \"\", *args, **kwargs)\n",
    "    return df\n",
    "\n",
    "\n",
    "@pf.register_dataframe_method\n",
    "def str_trim(df, column_name: str, *args, **kwargs):\n",
    "    \"\"\"Wrapper around df.str.strip\"\"\"\n",
    "\n",
    "    df[column_name] = df[column_name].str.strip(*args, **kwargs)\n",
    "    return df\n",
    "\n",
    "\n",
    "@pf.register_dataframe_method\n",
    "def explode(df: pd.DataFrame, column_name: str, sep: str):\n",
    "    \"\"\"\n",
    "    For rows with a list of values, this function will create new\n",
    "    rows for each value in the list\n",
    "    \"\"\"\n",
    "\n",
    "    df[\"id\"] = df.index\n",
    "    wdf = (\n",
    "        pd.DataFrame(df[column_name].str.split(sep).fillna(\"\").tolist())\n",
    "        .stack()\n",
    "        .reset_index()\n",
    "    )\n",
    "    # exploded_column = column_name\n",
    "    wdf.columns = [\"id\", \"depth\", column_name]  # plural form to singular form\n",
    "    # wdf[column_name] = wdf[column_name].apply(lambda x: x.strip())  # trim\n",
    "    wdf.drop(\"depth\", axis=1, inplace=True)\n",
    "\n",
    "    return pd.merge(df, wdf, on=\"id\", suffixes=(\"_drop\", \"\")).drop(\n",
    "        columns=[\"id\", column_name + \"_drop\"]\n",
    "    )\n",
    "\n",
    "\n",
    "@pf.register_dataframe_method\n",
    "def str_word(\n",
    "    df,\n",
    "    column_name: str,\n",
    "    start: int = None,\n",
    "    stop: int = None,\n",
    "    pat: str = \" \",\n",
    "    *args,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Wrapper around `df.str.split` with additional `start` and `end` arguments\n",
    "    to select a slice of the list of words.\n",
    "    \"\"\"\n",
    "\n",
    "    df[column_name] = df[column_name].str.split(pat).str[start:stop]\n",
    "    return df\n",
    "\n",
    "\n",
    "@pf.register_dataframe_method\n",
    "def str_join(df, column_name: str, sep: str, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Wrapper around `df.str.join`\n",
    "    Joins items in a list.\n",
    "    \"\"\"\n",
    "\n",
    "    df[column_name] = df[column_name].str.join(sep)\n",
    "    return df\n",
    "\n",
    "\n",
    "@pf.register_dataframe_method\n",
    "def str_slice(\n",
    "    df, column_name: str, start: int = None, stop: int = None, *args, **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Wrapper around `df.str.slice\n",
    "    \"\"\"\n",
    "\n",
    "    df[column_name] = df[column_name].str[start:stop]\n",
    "    return df\n",
    "\n",
    "\n",
    "clean_df = (\n",
    "    df.str_remove(column_name=\"producers\", pat=\"\\[|\\]\")\n",
    "    .explode(column_name=\"producers\", sep=\",\")\n",
    "    .str_remove(column_name=\"producers\", pat=\"'\")\n",
    "    .str_trim(\"producers\")\n",
    "    .str_remove(column_name=\"genre\", pat=\"\\[|\\]\")\n",
    "    .explode(column_name=\"genre\", sep=\",\")\n",
    "    .str_remove(column_name=\"genre\", pat=\"'\")\n",
    "    .str_trim(column_name=\"genre\")\n",
    "    .str_remove(column_name=\"studio\", pat=\"\\[|\\]\")\n",
    "    .explode(column_name=\"studio\", sep=\",\")\n",
    "    .str_remove(column_name=\"studio\", pat=\"'\")\n",
    "    .str_trim(column_name=\"studio\")\n",
    "    .str_remove(column_name=\"aired\", pat=\"\\{|\\}|'from':\\s*|'to':\\s*\")\n",
    "    .str_word(column_name=\"aired\", start=0, stop=2, pat=\",\")\n",
    "    .str_join(column_name=\"aired\", sep=\",\")\n",
    "    .deconcatenate_column(\n",
    "        column_name=\"aired\", new_column_names=[\"start_date\", \"end_date\"], sep=\",\"\n",
    "    )\n",
    "    .remove_columns(column_names=[\"aired\"])\n",
    "    .str_remove(column_name=\"start_date\", pat=\"'\")\n",
    "    .str_slice(column_name=\"start_date\", start=0, stop=10)\n",
    "    .str_remove(column_name=\"end_date\", pat=\"'\")\n",
    "    .str_slice(column_name=\"end_date\", start=0, stop=11)\n",
    "    .to_datetime(\"start_date\", format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "    .to_datetime(\"end_date\", format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "    .fill_empty(columns=[\"rank\", \"popularity\"], value=0)\n",
    "    .filter_on(\"rank != 0 & popularity != 0\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Data Dictionary\n",
    ">\n",
    ">Heads up the dataset is about 97 mb - if you want to free up some space, drop the synopsis and background, they are long strings, or broadcast, premiered, related as they are redundant or less useful.\n",
    ">\n",
    ">|variable       |class     |description |\n",
    "|:--------------|:---------|:-----------|\n",
    "|animeID        |double    | Anime ID (as in https://myanimelist.net/anime/animeID)          |\n",
    "|name           |character |anime title - extracted from the site.           |\n",
    "|title_english  |character | title in English (sometimes is different, sometimes is missing)          |\n",
    "|title_japanese |character | title in Japanese (if Anime is Chinese or Korean, the title, if available, in the respective language)          |\n",
    "|title_synonyms |character | other variants of the title         |\n",
    "|type           |character | anime type (e.g. TV, Movie, OVA)          |\n",
    "|source         |character | source of anime (i.e original, manga, game, music, visual novel etc.)         |\n",
    "|producers      |character | producers          |\n",
    "|genre          |character | genre         |\n",
    "|studio         |character | studio           |\n",
    "|episodes       |double    | number of episodes           |\n",
    "|status         |character | Aired or not aired      |\n",
    "|airing         |logical   | True/False is still airing          |\n",
    "|start_date     |double    | Start date (ymd)        |\n",
    "|end_date       |double    | End date (ymd)        |\n",
    "|duration       |character | Per episode duration or entire duration, text string        |\n",
    "|rating         |character | Age rating         |\n",
    "|score          |double    | Score (higher = better)       |\n",
    "|scored_by      |double    | Number of users that scored          |\n",
    "|rank           |double    | Rank - weight according to MyAnimeList formula          |\n",
    "|popularity     |double    |  based on how many members/users have the respective anime in their list          |\n",
    "|members        |double    | number members that added this anime in their list         |\n",
    "|favorites      |double    | number members that favorites these in their list          |\n",
    "|synopsis       |character | long string with anime synopsis          |\n",
    "|background     |character | long string with production background and other things          |\n",
    "|premiered      |character | anime premiered on season/year          |\n",
    "|broadcast      |character | when is (regularly) broadcasted         |\n",
    "|related        |character | dictionary: related animes, series, games etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/raw_anime.csv'\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Clean `producers` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step tries to clean up the `producers` column by removing some brackets ('[]') and trim off some empty spaces\n",
    "\n",
    ">```\n",
    ">clean_df <- raw_df %>% \n",
    ">  # Producers\n",
    ">  mutate(producers = str_remove(producers, \"\\\\[\"),\n",
    "         producers = str_remove(producers, \"\\\\]\"))\n",
    ">```\n",
    "\n",
    "What is mutate? This [link](https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_r.html) compares R's `mutate` to be similar to pandas' `df.assign`.\n",
    "However, `df.assign` returns a new DataFrame whereas `mutate` adds a new variable while preserving the previous ones.\n",
    "Therefore, for this example, I will compare `mutate` to be similar to `df['col'] = X`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this is looks like a list of items but in string form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what we trying to remove\n",
    "df.loc[df['producers'].str.contains(\"\\[\", na=False), 'producers'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use pandas flavor to create a custom method for just removing some strings so we don't have to use str.replace so many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pf.register_dataframe_method\n",
    "def str_remove(df, column_name: str, pat: str, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Wrapper around df.str.replace\n",
    "    The function will loop through regex patterns and remove them from the desired column.\n",
    "\n",
    "    :param df: A pandas DataFrame.\n",
    "    :param column_name: A `str` indicating which column the string removal action is to be made.\n",
    "    :param pat: A regex pattern to match and remove.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(pat, str):\n",
    "        raise TypeError(\n",
    "            f\"Pattern should be a valid regex pattern. Received pattern: {pat} with dtype: {type(pat)}\"\n",
    "        )\n",
    "    df[column_name] = df[column_name].str.replace(pat, \"\", *args, **kwargs)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = (\n",
    "    df\n",
    "    .str_remove(column_name='producers', pat='\\[|\\]')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With brackets removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['producers'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brackets are removed. Now the next part\n",
    ">```\n",
    ">  separate_rows(producers, sep = \",\") %>% \n",
    ">```\n",
    "\n",
    "It seems like separate rows will go through each value of the column, and if the value is a list, will create a new row for each value in the list with the remaining column values being the same. This is commonly known as an `explode` method but it is not yet implemented in pandas. We will need a function for this (code adopted from [here](https://qiita.com/rikima/items/c10e27d8b7495af4c159))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pf.register_dataframe_method\n",
    "def explode(df: pd.DataFrame, column_name: str, sep: str):\n",
    "    \"\"\"\n",
    "    For rows with a list of values, this function will create new rows for each value in the list\n",
    "\n",
    "    :param df: A pandas DataFrame.\n",
    "    :param column_name: A `str` indicating which column the string removal action is to be made.\n",
    "    :param sep: The delimiter. Example delimiters include `|`, `, `, `,` etc.\n",
    "    \"\"\"\n",
    "\n",
    "    df[\"id\"] = df.index\n",
    "    wdf = (\n",
    "        pd.DataFrame(df[column_name].str.split(sep).fillna(\"\").tolist())\n",
    "        .stack()\n",
    "        .reset_index()\n",
    "    )\n",
    "    # exploded_column = column_name\n",
    "    wdf.columns = [\"id\", \"depth\", column_name]  # plural form to singular form\n",
    "    # wdf[column_name] = wdf[column_name].apply(lambda x: x.strip())  # trim\n",
    "    wdf.drop(\"depth\", axis=1, inplace=True)\n",
    "\n",
    "    return pd.merge(df, wdf, on=\"id\", suffixes=(\"_drop\", \"\")).drop(\n",
    "        columns=[\"id\", column_name + \"_drop\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = (\n",
    "    clean_df\n",
    "    .explode(column_name='producers', sep=',')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now every producer is its own row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['producers'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now remove single quotes and a bit of trimming\n",
    ">```\n",
    "  mutate(producers = str_remove(producers, \"\\\\'\"),\n",
    "         producers = str_remove(producers, \"\\\\'\"),\n",
    "         producers = str_trim(producers)) %>% \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = (\n",
    "    clean_df\n",
    "    .str_remove(column_name='producers', pat='\\'')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll make another custom function for trimming whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pf.register_dataframe_method\n",
    "def str_trim(df, column_name: str, *args, **kwargs):\n",
    "    \"\"\"Remove trailing and leading characters, in a given column\"\"\"\n",
    "    df[column_name] = df[column_name].str.strip(*args, **kwargs)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_df.str_trim('producers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, here is our cleaned `producers` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['producers'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Clean `genre` and `studio` Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same process for columns `Genre` and `Studio`\n",
    "\n",
    ">```\n",
    ">  # Genre\n",
    "  mutate(genre = str_remove(genre, \"\\\\[\"),\n",
    "         genre = str_remove(genre, \"\\\\]\")) %>% \n",
    "  separate_rows(genre, sep = \",\") %>% \n",
    "  mutate(genre = str_remove(genre, \"\\\\'\"),\n",
    "         genre = str_remove(genre, \"\\\\'\"),\n",
    "         genre = str_trim(genre)) %>% \n",
    ">  # Studio\n",
    "  mutate(studio = str_remove(studio, \"\\\\[\"),\n",
    "         studio = str_remove(studio, \"\\\\]\")) %>% \n",
    "  separate_rows(studio, sep = \",\") %>% \n",
    "  mutate(studio = str_remove(studio, \"\\\\'\"),\n",
    "         studio = str_remove(studio, \"\\\\'\"),\n",
    "         studio = str_trim(studio)) %>% \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = (\n",
    "    clean_df\n",
    "    # Perform operation for genre.\n",
    "    .str_remove(column_name='genre', pat='\\[|\\]')\n",
    "    .explode(column_name='genre', sep=',')\n",
    "    .str_remove(column_name='genre', pat='\\'')\n",
    "    .str_trim(column_name='genre')\n",
    "    # Now do it for studio\n",
    "    .str_remove(column_name='studio', pat='\\[|\\]')\n",
    "    .explode(column_name='studio', sep=',')\n",
    "    .str_remove(column_name='studio', pat='\\'')\n",
    "    .str_trim(column_name='studio')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulting cleaned columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df[['genre', 'studio']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Clean `aired` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `aired` column has something a little different. In addition to the usual removing some strings and whitespace trimming, we want to separate the values into two separate columns `start_date` and `end_date`\n",
    "\n",
    ">```r\n",
    ">  # Aired\n",
    "  mutate(aired = str_remove(aired, \"\\\\{\"),\n",
    "         aired = str_remove(aired, \"\\\\}\"),\n",
    "         aired = str_remove(aired, \"'from': \"),\n",
    "         aired = str_remove(aired, \"'to': \"),\n",
    "         aired = word(aired, start = 1, 2, sep = \",\")) %>% \n",
    "  separate(aired, into = c(\"start_date\", \"end_date\"), sep = \",\") %>% \n",
    "  mutate(start_date = str_remove_all(start_date, \"'\"),\n",
    "         start_date = str_sub(start_date, 1, 10),\n",
    "         end_date = str_remove_all(start_date, \"'\"),\n",
    "         end_date = str_sub(end_date, 1, 10)) %>%\n",
    "  mutate(start_date = lubridate::ymd(start_date),\n",
    "         end_date = lubridate::ymd(end_date)) %>%\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create some custom wrapper functions to emulate R's `word` and use pyjanitor's `deconcatenate_column`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently looks like this\n",
    "clean_df['aired'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pf.register_dataframe_method\n",
    "def str_word(\n",
    "    df,\n",
    "    column_name: str,\n",
    "    start: int = None,\n",
    "    stop: int = None,\n",
    "    pat: str = \" \",\n",
    "    *args,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Wrapper around `df.str.split` with additional `start` and `end` arguments\n",
    "    to select a slice of the list of words.\n",
    "\n",
    "    :param df: A pandas DataFrame.\n",
    "    :param column_name: A `str` indicating which column the split action is to be made.\n",
    "    :param start: optional An `int` for the start index of the slice\n",
    "    :param stop: optinal  An `int` for the end index of the slice\n",
    "    :param pat: String or regular expression to split on. If not specified, split on whitespace.\n",
    "\n",
    "    \"\"\"\n",
    "    df[column_name] = df[column_name].str.split(pat).str[start:stop]\n",
    "    return df\n",
    "\n",
    "\n",
    "@pf.register_dataframe_method\n",
    "def str_join(df, column_name: str, sep: str, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Wrapper around `df.str.join`\n",
    "    Joins items in a list.\n",
    "\n",
    "    :param df: A pandas DataFrame.\n",
    "    :param column_name: A `str` indicating which column the split action is to be made.\n",
    "    :param sep: The delimiter. Example delimiters include `|`, `, `, `,` etc.\n",
    "    \"\"\"\n",
    "    df[column_name] = df[column_name].str.join(sep)\n",
    "    return df\n",
    "\n",
    "\n",
    "@pf.register_dataframe_method\n",
    "def str_slice(\n",
    "    df, column_name: str, start: int = None, stop: int = None, *args, **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Wrapper around `df.str.slice\n",
    "    Slices strings.\n",
    "\n",
    "    :param df: A pandas DataFrame.\n",
    "    :param column_name: A `str` indicating which column the split action is to be made.\n",
    "    :param start: 'int' indicating start of slice.\n",
    "    :param stop: 'int' indicating stop of slice.\n",
    "    \"\"\"\n",
    "    df[column_name] = df[column_name].str[start:stop]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = (\n",
    "    clean_df.str_remove(column_name=\"aired\", pat=\"\\{|\\}|'from':\\s*|'to':\\s*\")\n",
    "    .str_word(column_name=\"aired\", start=0, stop=2, pat=\",\")\n",
    "    .str_join(column_name=\"aired\", sep=\",\")\n",
    "    # .add_columns({'start_date': clean_df['aired'][0]})\n",
    "    .deconcatenate_column(\n",
    "        column_name=\"aired\", new_column_names=[\"start_date\", \"end_date\"], sep=\",\"\n",
    "    )\n",
    "    .remove_columns(column_names=[\"aired\"])\n",
    "    .str_remove(column_name=\"start_date\", pat=\"'\")\n",
    "    .str_slice(column_name=\"start_date\", start=0, stop=10)\n",
    "    .str_remove(column_name=\"end_date\", pat=\"'\")\n",
    "    .str_slice(column_name=\"end_date\", start=0, stop=11)\n",
    "    .to_datetime(\"start_date\", format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "    .to_datetime(\"end_date\", format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resulting 'start_date' and 'end_date' columns with 'aired' column removed\n",
    "clean_df[['start_date', 'end_date']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Filter out unranked and unpopular series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's drop the unranked or unpopular series with pyjanitor's `filter_on`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First fill any NA values with 0 and then filter != 0\n",
    "clean_df = clean_df.fill_empty(column_names=[\"rank\", \"popularity\"], value=0).filter_on(\n",
    "    \"rank != 0 & popularity != 0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
